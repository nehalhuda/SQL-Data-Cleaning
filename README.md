# ğŸ§¹ SQL Data Cleaning and Analysis Project

## ğŸ“– Overview
This project demonstrates my SQL skills through a complete data cleaning and exploratory analysis workflow.  
The dataset focuses on company layoffs and simulates real-world messy data scenarios â€” including duplicates, missing values, inconsistent formatting, and invalid entries.  

The goal was to transform raw data into a reliable, analysis-ready format and uncover insights into layoff patterns across industries, countries, and company stages.  
This project reflects how SQL can be used for both **data engineering** and **data analysis** tasks.

---

## ğŸ—‚ï¸ Project Structure
```plaintext
sql-project/
â”œâ”€â”€ schema.sql        # Table creation and schema definition
â”œâ”€â”€ inserts.sql       # Sample data population script
â”œâ”€â”€ cleaning.sql      # Data cleaning and transformation queries
â”œâ”€â”€ analysis.sql      # Analytical and exploratory SQL queries
â””â”€â”€ README.md         # Project documentation

---

## ğŸ§  Skills & Concepts Used

### ğŸ§¹ Data Cleaning
- Removed duplicate records using `ROW_NUMBER()` and CTEs  
- Handled `NULL` and blank values with conditional updates  
- Standardized inconsistent data entries (e.g., trimming spaces, fixing date formats, cleaning country and industry names)  
- Removed irrelevant records for cleaner analysis  

### ğŸ” Filtering & Selection
- Used `WHERE`, `LIKE`, `BETWEEN`, and `IN` for conditional filtering  
- Extracted meaningful subsets of data based on company size, industry, or region  

### ğŸ“Š Aggregations & Grouping
- Summarized data using `COUNT`, `SUM`, `AVG`, `MIN`, and `MAX`  
- Grouped results with `GROUP BY` and refined analysis using `HAVING`  

### ğŸ”— Joins & Relationships
- Connected related tables using `INNER JOIN` and `LEFT JOIN`  
- Validated data integrity across sources  

### ğŸ§© Subqueries & CTEs
- Created nested queries for complex filtering  
- Improved readability and maintainability with `WITH` clauses  

### ğŸªœ Window Functions
- Used `ROW_NUMBER()` for identifying duplicates  
- Applied ranking functions for advanced insights (e.g., top companies or countries by layoffs)

---

## ğŸ“ˆ Key Outcomes
- Cleaned and standardized over **10,000+ records** for consistent analysis  
- Identified **trends in layoffs** across industries and countries  
- Enhanced data reliability by removing duplicate and incomplete records  
- Created **reusable SQL scripts** for data cleaning and analytics workflows  

---

## ğŸš€ How to Use
1. **Clone the repository**  
   ```bash
   git clone https://github.com/<your-username>/sql-data-cleaning-project.git
   cd sql-data-cleaning-project

2. Import SQL files into your MySQL or PostgreSQL environment.

3. Run scripts in order:
schema.sql,
inserts.sql,
cleaning.sql,
analysis.sql,

4. Explore and modify queries to perform your own analysis or connect results to visualization tools like Power BI or Tableau.
